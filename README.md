# üì∏ SnapShop ‚Äî See It. Identify It. Buy It with USDC.

> **Point your camera at any product ‚Üí AI identifies it instantly ‚Üí Shop across Amazon, eBay & AliExpress ‚Üí Pay with USDC on Solana**

[![Solana Mobile](https://img.shields.io/badge/Solana_Mobile-Seeker_Ready-9945FF?style=for-the-badge&logo=solana)](https://solanamobile.com)
[![Android](https://img.shields.io/badge/Android-Native-3DDC84?style=for-the-badge&logo=android)](https://developer.android.com)
[![AI Powered](https://img.shields.io/badge/AI-Gemini_Vision-4285F4?style=for-the-badge&logo=google)](https://ai.google.dev)
[![USDC](https://img.shields.io/badge/Pay_with-USDC-2775CA?style=for-the-badge)](https://www.circle.com/usdc)

---

## üéØ The Problem

**Shopping in the real world is disconnected from the crypto world.**

You see a product you like ‚Äî a pair of sneakers someone is wearing, a gadget on a desk, a piece of furniture in a cafe. Today, you have to:
1. Figure out what it is (Google it? Ask someone?)
2. Search for it manually on shopping sites
3. Pay with fiat (credit cards, bank transfers)

There's no bridge between **"I see it with my eyes"** and **"I buy it with my crypto wallet."**

## üí° The Solution

**SnapShop** turns your Solana Mobile phone into an AI-powered shopping assistant:

```
üì∑ Point Camera ‚Üí ü§ñ AI Identifies Product ‚Üí üõí Shop Instantly ‚Üí üí∞ Pay with USDC
     (Real-time)     (Brand + Model + Color)   (Amazon/eBay/Ali)    (Solana Blockchain)
```

One seamless flow. No typing. No searching. See it, snap it, buy it ‚Äî all on-chain.

---

## ‚ú® Key Features

### üîç Dual AI Vision Engine
- **On-Device YOLO26**: Real-time object detection at 10-13 FPS using NCNN ‚Äî bounding boxes appear instantly, no network required
- **Cloud LLM Identification**: Tiered cascade strategy using Gemini via OpenRouter ‚Äî identifies specific brands, models, and variants (e.g., "Apple iPhone 16 Pro Max Natural Titanium", not just "phone")

### üß† Smart Tiered Cascade
| Tier | Model | Cost | When Used |
|------|-------|------|-----------|
| **Tier 1** | Gemini 2.5 Flash-Lite | ~$0.10/1K images | Default ‚Äî fast, cheap |
| **Tier 2** | Configurable (Gemini 3 Flash) | ~$0.50/1K images | Auto-upgrades when confidence < 60% |

> **65x cheaper** than Google Cloud Vision API ($6.50/1K) while delivering **brand + model level** identification

### üõí Multi-Platform Shopping
- **Amazon** ‚Äî Smart routing: tries native app first, falls back to in-app WebView
- **eBay** ‚Äî Full in-app browsing experience
- **AliExpress** ‚Äî Global product access
- All shopping happens **inside the app** ‚Äî no context switching

### üí∞ USDC Payments via Solana
- **Wallet Connection**: Mobile Wallet Adapter (MWA) integration with Seeker/Seed Vault
- **USDC Balance**: Real-time SPL token balance display
- **Buy with USDC**: Bitrefill integration for Amazon gift cards ‚Üí pay with USDC on Solana
- **On-Chain Receipts**: Detection data recorded as Solana Memo transactions ‚Äî immutable shopping history

### üîí Privacy-First Architecture
- **Images never leave your device** for YOLO detection
- Cloud LLM receives only compressed thumbnails (‚â§384px) ‚Äî no full-resolution photos
- On-chain memos contain only detection metadata, never images
- No user accounts, no tracking, no data collection

---

## üèóÔ∏è Architecture

```mermaid
flowchart TB
    subgraph CAM["üì∑ Camera Layer"]
        A["CameraX\n(Real-time Feed)"] -->|"ÊØèÂ∏ß ~70ms"| B["YOLO26 NCNN\n(On-Device, 10-13 FPS)"]
        B --> C["Bounding Boxes\n(OverlayView)"]
    end

    A -->|"üì∏ User Tap Capture"| D

    subgraph LLM["ü§ñ LLM Vision Engine (OpenRouter)"]
        D["Resize ‚â§384px\nJPEG 80% + Base64"] --> E["Tier 1: Gemini\nFlash-Lite\n~$0.10/1K images"]
        E -->|"confidence < 60%\nor model empty"| F["Tier 2: Auto-Upgrade\n(Configurable Model)"]
        E --> G["{ brand, model,\ncategory, searchQuery,\nconfidence }"]
        F --> G
    end

    subgraph SHOP["üõí Shopping Layer (In-App WebView)"]
        H["Amazon\n(Chrome UA)"]
        I["eBay"]
        J["AliExpress"]
    end

    G --> H
    G --> I
    G --> J

    subgraph SOL["‚õìÔ∏è Solana Blockchain"]
        K["MWA Wallet\n(Seeker/Seed Vault)"]
        L["USDC Payments\n(SPL Token)"]
        M["Memo On-Chain\n(Detection Receipts)"]
    end

    H -->|"Buy with USDC"| N["Bitrefill\n(Gift Cards)"]
    N --> L
    K --> L
    K --> M
    B -->|"Detection Data"| M

    style CAM fill:#1a1a2e,stroke:#00d2ff,color:#fff
    style LLM fill:#1a1a2e,stroke:#ff6b6b,color:#fff
    style SHOP fill:#1a1a2e,stroke:#4ecdc4,color:#fff
    style SOL fill:#1a1a2e,stroke:#9945ff,color:#fff
```

---

## üöÄ User Flow

### Flow 1: SnapShop (AI Shopping)
1. **Open Camera** ‚Üí YOLO26 draws real-time bounding boxes around objects
2. **Tap Capture** ‚Üí Frame is sent to LLM Vision Engine
3. **AI Identifies** ‚Üí "Apple iPhone 16 Pro Max" with 92% confidence
4. **Choose Platform** ‚Üí Amazon / eBay / AliExpress
5. **Shop In-App** ‚Üí Full WebView browser, no app switching
6. **Pay with USDC** ‚Üí Bitrefill gift card purchase via Solana wallet

### Flow 2: Detect & On-Chain
1. **Real-time Detection** ‚Üí YOLO26 identifies objects at 10-13 FPS
2. **Tap "On-Chain"** ‚Üí Detection results serialized to compact JSON
3. **Sign with MWA** ‚Üí Seeker wallet signs the Memo transaction
4. **Recorded Forever** ‚Üí Immutable detection record on Solana blockchain
5. **View on Explorer** ‚Üí Direct link to Solana Explorer

---

## üì± Screenshots

> *Coming soon ‚Äî see [Demo Video](#demo) for the full experience*

---

## üõ†Ô∏è Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Object Detection** | YOLO26n + NCNN | Real-time on-device detection (CPU/GPU) |
| **AI Identification** | Gemini Flash via OpenRouter | Brand + model level product ID |
| **Camera** | CameraX 1.3.1 | Modern Android camera API |
| **Blockchain** | Solana Web3 + MWA 2.0.3 | Wallet connection, transactions |
| **Payments** | USDC (SPL Token) | Stablecoin payments |
| **Shopping** | In-App WebView | Amazon, eBay, AliExpress |
| **Gift Cards** | Bitrefill | USDC ‚Üí Amazon gift cards |
| **Native Code** | C++ / CMake / NDK | YOLO inference engine |
| **Languages** | Java + Kotlin | Android app code |
| **Image Processing** | OpenCV Mobile | Frame preprocessing |

---

## üì¶ Getting Started

### Prerequisites
- Android Studio Hedgehog or newer
- Android SDK 24+ (target 34)
- NDK with CMake support
- A Solana wallet app (Seed Vault / Phantom) for blockchain features

### 1. Clone the Repository
```bash
git clone https://github.com/alertcat/SnapShop.git
cd SnapShop
```

### 2. Configure API Keys

Create or edit `local.properties` in the project root:

```properties
# LLM Vision (required for product identification)
OPENROUTER_API_KEY=your_openrouter_api_key
OPENROUTER_MODEL=google/gemini-3-flash-preview

# Google Vision API (optional legacy fallback)
GOOGLE_VISION_API_KEY=your_google_vision_key

# Shopping
AMAZON_AFFILIATE_TAG=your_tag

# Solana
MERCHANT_WALLET_ADDRESS=your_solana_address
```

> Get your OpenRouter API key at [openrouter.ai/keys](https://openrouter.ai/keys) ‚Äî Gemini Flash-Lite costs ~$0.0001 per image

### 3. Download Native Dependencies

**NCNN** ‚Äî Download from [ncnn releases](https://github.com/Tencent/ncnn/releases):
```
ncnn-YYYYMMDD-android-vulkan.zip ‚Üí extract to app/src/main/jni/ncnn-android-vulkan/
```

**OpenCV Mobile** ‚Äî Download from [opencv-mobile releases](https://github.com/nihui/opencv-mobile/releases):
```
opencv-mobile-4.10.0-android.zip ‚Üí extract to app/src/main/jni/
```

### 4. Place YOLO Model Files
```
app/src/main/assets/
‚îú‚îÄ‚îÄ yolo26n.ncnn.param
‚îî‚îÄ‚îÄ yolo26n.ncnn.bin
```

Export from Ultralytics:
```python
from ultralytics import YOLO
model = YOLO("yolo26n.pt")
model.export(format="ncnn")
```

### 5. Build & Run
```bash
./gradlew assembleDebug
```

Install on your Solana Seeker or any Android device (API 24+).

---

## üîó Solana Integration Details

### Mobile Wallet Adapter (MWA)
```kotlin
// Connect to Seeker wallet
val walletAdapter = MobileWalletAdapter(
    connectionIdentity = ConnectionIdentity(
        identityUri = Uri.parse("https://snapshop.app"),
        identityName = "SnapShop"
    )
)
```

### On-Chain Memo Format
Detection results are recorded on Solana's Memo Program as compact JSON:
```json
{
  "t": "yolo26",
  "v": 1,
  "n": 3,
  "d": [
    {"c": "person", "p": 0.95, "b": [10, 20, 100, 200]},
    {"c": "laptop", "p": 0.88, "b": [150, 50, 300, 250]}
  ]
}
```

### USDC Payment Flow
```
User's Solana Wallet (USDC)
         ‚îÇ
         ‚ñº
    Bitrefill.com (in-app WebView)
         ‚îÇ
         ‚ñº
    Amazon Gift Card (instant delivery)
         ‚îÇ
         ‚ñº
    Purchase product on Amazon
```

### Programs Used
| Program | Address |
|---------|---------|
| Memo Program | `MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr` |
| USDC Mint | `EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v` |
| Token Program | `TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA` |
| ATA Program | `ATokenGPvbdGVxr1b2hvZbsiqW5xWH25efTNsLJA8knL` |

---

## ü§ñ LLM Vision Engine Deep Dive

### Why LLM over Traditional Vision APIs?

| Approach | Identifies | Cost/1K | Example Output |
|----------|-----------|---------|----------------|
| Google Vision API | Generic labels | $6.50 | "Mobile Phone, Electronics" |
| Amazon Rekognition | Generic labels | $1.00 | "Phone, Gadget" |
| **SnapShop LLM Engine** | **Brand + Model** | **$0.10** | **"Apple iPhone 16 Pro Max"** |

Traditional vision APIs use fixed label taxonomies ‚Äî they can't distinguish an iPhone from a Samsung. Multimodal LLMs have world knowledge and can identify specific products just like a human would. And when the exact model is unknown (due to knowledge cutoff), SnapShop's attribute-based approach still finds the right product.

### Knowledge Cutoff & Anti-Hallucination Design

LLMs have training data cutoff dates ‚Äî they can't identify products released after training. For example, a model trained before iPhone 16 might misidentify it as iPhone 14.

**SnapShop solves this with attribute-based identification:**

```
Instead of guessing: "iPhone 14 Pro Max Gold"     ‚Üê WRONG model!
SnapShop describes:   "Apple iPhone Pro Max Desert Titanium triple camera"  ‚Üê Matches correctly!
```

The system prompt injects the **current system date** and instructs the LLM to:

| Strategy | How It Works |
|----------|-------------|
| **Describe, don't guess** | Focus on observable attributes (color, camera layout, material, form factor) |
| **Never hallucinate model numbers** | Leave `model` empty when uncertain ‚Äî wrong model is worse than no model |
| **Attribute-based searchQuery** | Build search query from physical features, not guessed generations |
| **Confidence gating** | Only include model number in fallback search if confidence ‚â• 85% |
| **Low temperature (0.1)** | Near-deterministic output, minimizes creative guessing |

This ensures shopping platforms match the **correct product** regardless of LLM knowledge cutoff.

### Token Optimization
- Images resized to ‚â§384px ‚Üí only **258 tokens** in Gemini
- JPEG compression at 80% quality
- Max 500 output tokens (structured JSON response)
- **Total cost per identification: ~$0.0001**

---

## üìä Performance

| Metric | Value |
|--------|-------|
| YOLO26 FPS (CPU) | 10-13 FPS |
| YOLO26 FPS (GPU/Vulkan) | ~4 FPS |
| LLM Identification Latency | < 2 seconds |
| LLM Cost per Image | ~$0.0001 (Tier 1) |
| Supported Architectures | arm64-v8a, armeabi-v7a |
| Min SDK | Android 7.0 (API 24) |
| Target SDK | Android 14 (API 34) |

### Tested Devices
| Device | CPU FPS | Notes |
|--------|---------|-------|
| Solana Seeker (Dimensity 7300) | ~13 FPS | Primary target device |
| Huawei P40 (Kirin 990) | ~10 FPS | CPU mode recommended |

---

## üóÇÔ∏è Project Structure

```
app/src/main/
‚îú‚îÄ‚îÄ java/com/example/snapshop/
‚îÇ   ‚îú‚îÄ‚îÄ MainActivity.java          # Home screen + wallet connection
‚îÇ   ‚îú‚îÄ‚îÄ DetectActivity.java        # YOLO detection + on-chain memo
‚îÇ   ‚îú‚îÄ‚îÄ ShopCameraActivity.java    # AI shopping camera
‚îÇ   ‚îú‚îÄ‚îÄ ProductResultsActivity.java # Shopping platform selection
‚îÇ   ‚îú‚îÄ‚îÄ ShopWebViewActivity.java   # In-app shopping browser
‚îÇ   ‚îú‚îÄ‚îÄ OverlayView.java          # Real-time bounding box renderer
‚îÇ   ‚îú‚îÄ‚îÄ Yolo26Ncnn.java           # JNI bridge to NCNN engine
‚îÇ   ‚îú‚îÄ‚îÄ LlmVisionHelper.kt       # Tiered LLM product identification
‚îÇ   ‚îú‚îÄ‚îÄ VisionApiHelper.kt       # Google Vision API (legacy fallback)
‚îÇ   ‚îú‚îÄ‚îÄ WalletHelper.kt          # Solana MWA + memo + USDC
‚îÇ   ‚îú‚îÄ‚îÄ ShopHelper.kt            # Shopping URL builder
‚îÇ   ‚îî‚îÄ‚îÄ CustomTabHelper.kt       # Chrome Custom Tabs (fallback)
‚îú‚îÄ‚îÄ jni/
‚îÇ   ‚îú‚îÄ‚îÄ yolo.cpp / yolo.h        # YOLO26 NCNN inference engine
‚îÇ   ‚îú‚îÄ‚îÄ yolo26ncnn.cpp            # JNI bindings
‚îÇ   ‚îî‚îÄ‚îÄ CMakeLists.txt            # Native build config
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îú‚îÄ‚îÄ yolo26n.ncnn.param        # YOLO model architecture
‚îÇ   ‚îî‚îÄ‚îÄ yolo26n.ncnn.bin          # YOLO model weights
‚îî‚îÄ‚îÄ res/
    ‚îî‚îÄ‚îÄ layout/                    # All activity layouts (dark theme)
```

---

## üèÜ Why SnapShop for Solana Mobile?

1. **Real-World Utility**: Bridges physical shopping with crypto payments ‚Äî a use case billions of smartphone users can relate to
2. **Mobile-First**: Built from the ground up for Solana Mobile Stack ‚Äî not a ported web app
3. **Seeker-Native**: MWA wallet integration, optimized for Seeker hardware
4. **AI + Blockchain Convergence**: Combines cutting-edge multimodal AI with on-chain transparency
5. **Cost Innovation**: 65x cheaper than traditional vision APIs while delivering superior results
6. **Privacy-Preserving**: No image uploads for detection, no user tracking, on-chain data is only metadata
7. **dApp Store Ready**: Standalone Android APK, no browser required, native mobile experience
8. **USDC Economy**: Demonstrates real USDC utility ‚Äî from AI identification to purchase completion

---

## üó∫Ô∏è Roadmap

- [ ] **Solana dApp Store** submission
- [ ] **Solana Pay** direct integration (skip gift card step)
- [ ] **AR Shopping Overlay** ‚Äî prices floating above detected products
- [ ] **Multi-product** identification in single frame
- [ ] **Price comparison** across platforms
- [ ] **Shopping history** on-chain (encrypted memos)
- [ ] **Social sharing** ‚Äî share finds with friends via Solana Blinks
- [ ] **Merchant SDK** ‚Äî let sellers accept USDC directly through SnapShop

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## üìÑ License

This project is licensed under the MIT License.

---

<div align="center">

**Built for [Monolith ‚Äî Solana Mobile Hackathon](https://solanamobile.radiant.nexus/?panel=hackathon)**

*See it. Snap it. Buy it ‚Äî on Solana.*

üõí **SnapShop** | üì∑ AI Vision | ‚õìÔ∏è On-Chain | üí∞ USDC Payments

</div>
